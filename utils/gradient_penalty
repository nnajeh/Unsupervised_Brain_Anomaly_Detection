def compute_gradient_penalty(D, real_samples, fake_samples):
    alpha = torch.rand(*real_samples.shape[:2], 1, 1).to(device)
    interpolates = (alpha * real_samples + (1 - alpha) * fake_samples)

    interpolates = autograd.Variable(interpolates, requires_grad=True)

    d_interpolates = D(interpolates)
    fake = torch.ones(*d_interpolates.shape).to(device)

    gradients = autograd.grad(outputs=d_interpolates, inputs=interpolates,
                              grad_outputs=fake, create_graph=True,
                              retain_graph=True, only_inputs=True)[0]

    gradients = gradients.view(gradients.shape[0], -1)

    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()

    return gradient_penalty
