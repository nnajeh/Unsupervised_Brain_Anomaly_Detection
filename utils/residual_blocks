class GResidualBlock(nn.Module):

    def __init__(self,in_channels, out_channels, upsample = True):
        super().__init__()

        self.conv1 = DepthwiseSeparableConv(in_channels, out_channels, kernel_size=3, padding= 1)
        self.conv2 = DepthwiseSeparableConv(out_channels, out_channels, kernel_size=3, padding=1)

        self.bn1 = nn.BatchNorm2d(in_channels)
        self.bn2 = nn.BatchNorm2d(out_channels)

        self.activation = nn.ReLU(inplace = False)
        self.upsample = upsample
        self.upsample_fn = nn.Upsample(scale_factor=2)     

        self.mixin = (in_channels != out_channels) or upsample
        if self.mixin:
            self.conv_mixin = DepthwiseSeparableConv(in_channels, out_channels, kernel_size=1, padding=0)


    def forward(self, x):

        h = self.bn1(x)
        h = self.activation(h)
        h = self.upsample_fn(h)
        x = self.upsample_fn(x)
        h = self.conv1(h)

        h = self.bn2(h)
        h = self.activation(h)
        h = self.conv2(h)

        if self.mixin:
            x = self.conv_mixin(x)

        return h + x





class DResidualBlock(nn.Module):

    def __init__(self, in_channels, out_channels, downsample=True, use_preactivation=False, hw = 64 ):
        super().__init__()

        self.conv1 = DepthwiseSeparableConv(in_channels, out_channels, kernel_size=3, padding=1)
        self.conv2 = DepthwiseSeparableConv(out_channels, out_channels, kernel_size=3, padding=1)

        self.bn = nn.InstanceNorm2d(out_channels)


        self.activation = nn.ReLU()
        self.use_preactivation = use_preactivation  

        self.downsample = downsample    

        if downsample:
            self.downsample_fn = nn.AvgPool2d(2)
        self.mixin = (in_channels != out_channels) or downsample

        if self.mixin:
            self.conv_mixin = DepthwiseSeparableConv(in_channels, out_channels, kernel_size=1, padding=0)

    def _residual(self, x):
        if self.use_preactivation:
            if self.mixin:
                x = self.conv_mixin(x)
            if self.downsample:
                x = self.downsample_fn(x)
        else:
            if self.downsample:
                x = self.downsample_fn(x)
            if self.mixin:
                x = self.conv_mixin(x)
        return x

    def forward(self, x):
        # Apply preactivation if applicable
        if self.use_preactivation:
            h = F.relu(x)
        else:
            h = x
        h = self.bn(h)
        h = self.activation(h)
        h = self.conv1(h)

        h = self.bn(h)
        h = self.activation(h)
        h = self.conv2(h)

        if self.downsample:
            h = self.downsample_fn(h)

        return h + self._residual(x)
